{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ДЗ26 Власов АЛ",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOUDZewEzLWn"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1g-tBeFP38Rp"
      },
      "source": [
        "# **Import библиотек**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j1Wpkvc3Q2s"
      },
      "source": [
        "from google.colab import files # модуль для загрузки файлов в colab\n",
        "import numpy as np #библиотека для работы с массивами данных\n",
        "\n",
        "from tensorflow.keras.models import Model, load_model # из кераса подгружаем абстрактный класс базовой модели, метод загрузки предобученной модели\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Input # из кераса загружаем необходимые слои для нейросети\n",
        "from tensorflow.keras.optimizers import RMSprop, Adadelta # из кераса загружаем выбранный оптимизатор\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences # загружаем метод ограничения последовательности заданной длиной\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer # загружаем токенизатор кераса для обработки текста\n",
        "from tensorflow.keras import utils # загружаем утилиты кераса для one hot кодировки\n",
        "from tensorflow.keras.utils import plot_model # удобный график для визуализации архитектуры модели\n",
        "import re\n",
        "import yaml # импортируем модуль для удобной работы с файлами"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "200dSPOYZE7N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "619770cd-b569-4c51-ee02-08ec86bee244"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M36i8ayPPLhX"
      },
      "source": [
        "# LIGHT-1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wxdi0Fqeg1LH"
      },
      "source": [
        "## **Парсинг данных**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEA8TR_oerov",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b366760-1612-4e49-fca1-1779aee1fb13"
      },
      "source": [
        "######################\n",
        "# Открываем файл с диалогами\n",
        "######################\n",
        "corpus = open('/content/drive/My Drive/26 Генерация текста/Диалоги(рассказы).yml', 'r') # открываем файл с диалогами в режиме чтения\n",
        "document = yaml.safe_load(corpus) # загружаем файл *глоссарий\n",
        "conversations = document['разговоры'] # загружаем диалоги из файла и заносим в conversations \n",
        "print('Количество пар вопрос-ответ : {}'.format(len(conversations)))\n",
        "print('Пример диалога : {}'.format(conversations[123]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Количество пар вопрос-ответ : 11905\n",
            "Пример диалога : ['Перезалил?', 'Да вроде бы нет...']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYg8z8Vj76bu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d152838-b034-4142-d6ac-7b5d0095d844"
      },
      "source": [
        "######################\n",
        "# Разбираем вопросы-ответы с проставлением тегов ответам\n",
        "######################\n",
        "# Собираем вопросы и ответы в списки\n",
        "questions = list() # здесь будет список вопросов\n",
        "answers = list() # здесь будет список ответов\n",
        "\n",
        "# В каждом диалоге берем фразу и добавляем в лист\n",
        "# Если в ответе не одна фраза - то сцепляем сколько есть\n",
        "for con in conversations: # для каждой пары вопрос-ответ\n",
        "  if len(con) > 2 : # если ответ содержит более двух предложений (кол-во реплик, кол-во вариантов ответа)\n",
        "    questions.append(con[0]) # то вопросительную реплику отправляем в список вопросов\n",
        "    replies = con[1:] # а ответную составляем из последующих строк\n",
        "    ans = '' # здесь соберем ответ\n",
        "    for rep in replies: # каждую реплику в ответной реплике\n",
        "      ans += ' ' + rep \n",
        "    answers.append(ans) #добавим в список ответов\n",
        "  elif len(con)> 1: # если на 1 вопрос приходится 1 ответ\n",
        "    questions.append(con[0]) # то вопросительную реплику отправляем в список вопросов\n",
        "    answers.append(con[1]) # а ответную в список ответов\n",
        "\n",
        "# Очищаем строки с неопределенным типов ответов\n",
        "answersCleaned = list()\n",
        "for i in range(len(answers)):\n",
        "  if type(answers[i]) == str:\n",
        "    answersCleaned.append(answers[i]) #если тип - строка, то добавляем в ответы\n",
        "  else:\n",
        "    questions.pop(i) # если не строка, то ответ не добавился, и плюс убираем соответствующий вопрос\n",
        "\n",
        "# Сделаем теги-метки для начала и конца ответов\n",
        "answers = list()\n",
        "for i in range(len(answersCleaned)):\n",
        "  answers.append( '<START> ' + answersCleaned[i] + ' <END>' )\n",
        "\n",
        "# Выведем обновленные данные на экран\n",
        "print('Вопрос : {}'.format(questions[200]))\n",
        "print('Ответ : {}'.format(answers[200]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Вопрос : Около сотни...\n",
            "Ответ : <START> Точнее! <END>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvn1jvRd9tep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1572ac2-b55a-4ca3-fcd8-7e40bd5d24b1"
      },
      "source": [
        "######################\n",
        "# Подключаем керасовский токенизатор и собираем словарь индексов\n",
        "######################\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(questions + answers) # загружаем в токенизатор список вопросов-ответов для сборки словаря частотности\n",
        "vocabularyItems = list(tokenizer.word_index.items()) # список с cодержимым словаря\n",
        "vocabularySize = len(vocabularyItems)+1 # размер словаря\n",
        "print( 'Фрагмент словаря : {}'.format(vocabularyItems[:50]))\n",
        "print( 'Размер словаря : {}'.format(vocabularySize))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Фрагмент словаря : [('start', 1), ('end', 2), ('что', 3), ('не', 4), ('я', 5), ('а', 6), ('ты', 7), ('это', 8), ('да', 9), ('в', 10), ('нет', 11), ('как', 12), ('и', 13), ('вы', 14), ('ну', 15), ('с', 16), ('на', 17), ('же', 18), ('так', 19), ('он', 20), ('у', 21), ('кто', 22), ('где', 23), ('все', 24), ('мы', 25), ('то', 26), ('мне', 27), ('тебя', 28), ('меня', 29), ('здесь', 30), ('еще', 31), ('почему', 32), ('о', 33), ('там', 34), ('тебе', 35), ('есть', 36), ('его', 37), ('за', 38), ('куда', 39), ('вот', 40), ('ничего', 41), ('вас', 42), ('знаю', 43), ('чем', 44), ('но', 45), ('она', 46), ('они', 47), ('ли', 48), ('чего', 49), ('вам', 50)]\n",
            "Размер словаря : 15104\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsUqzEBXg9Mu"
      },
      "source": [
        "## **Подготовка выборки**\n",
        "\n",
        "*Разбор данного раздела:* https://youtu.be/LV-ScxAqnMY?t=4906"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4nNBJUQgebF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abb14a0e-38e4-4446-fc09-1379bbe9877a"
      },
      "source": [
        "######################\n",
        "# Устанавливаем закодированные входные данные(вопросы)\n",
        "######################\n",
        "tokenizedQuestions = tokenizer.texts_to_sequences(questions) # разбиваем текст вопросов на последовательности индексов\n",
        "maxLenQuestions = max([ len(x) for x in tokenizedQuestions]) # уточняем длину самого большого вопроса\n",
        "# Делаем последовательности одной длины, заполняя нулями более короткие вопросы\n",
        "paddedQuestions = pad_sequences(tokenizedQuestions, maxlen=maxLenQuestions, padding='post')\n",
        "\n",
        "# Предподготавливаем данные для входа в сеть\n",
        "encoderForInput = np.array(paddedQuestions) # переводим в numpy массив\n",
        "print('Пример оригинального вопроса на вход : {}'.format(questions[100])) \n",
        "print('Пример кодированного вопроса на вход : {}'.format(encoderForInput[100])) \n",
        "print('Размеры закодированного массива вопросов на вход : {}'.format(encoderForInput.shape)) \n",
        "print('Установленная длина вопросов на вход : {}'.format(maxLenQuestions)) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Пример оригинального вопроса на вход : Какая же мораль?\n",
            "Пример кодированного вопроса на вход : [ 170   18 5709    0    0    0    0    0    0    0    0]\n",
            "Размеры закодированного массива вопросов на вход : (11900, 11)\n",
            "Установленная длина вопросов на вход : 11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tjvhMuzqFJD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11e78e81-570c-4039-b4d5-eccf7d079298"
      },
      "source": [
        "######################\n",
        "# Устанавливаем раскодированные входные данные(ответы)\n",
        "######################\n",
        "tokenizedAnswers = tokenizer.texts_to_sequences(answers) # разбиваем текст ответов на последовательности индексов\n",
        "maxLenAnswers = max([len(x) for x in tokenizedAnswers]) # уточняем длину самого большого ответа\n",
        "# Делаем последовательности одной длины, заполняя нулями более короткие ответы\n",
        "paddedAnswers = pad_sequences(tokenizedAnswers, maxlen=maxLenAnswers, padding='post')\n",
        "\n",
        "# Предподготавливаем данные для входа в сеть\n",
        "decoderForInput = np.array(paddedAnswers) # переводим в numpy массив\n",
        "print('Пример оригинального ответа на вход: {}'.format(answers[100])) \n",
        "print('Пример раскодированного ответа на вход : {}'.format(decoderForInput[100][:30])) \n",
        "print('Размеры раскодированного массива ответов на вход : {}'.format(decoderForInput.shape)) \n",
        "print('Установленная длина ответов на вход : {}'.format(maxLenAnswers)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Пример оригинального ответа на вход: <START> Никакой. Так просто вспомнилось. <END>\n",
            "Пример раскодированного ответа на вход : [    1   673    19    93 10558     2     0     0     0     0     0     0\n",
            "     0]\n",
            "Размеры раскодированного массива ответов на вход : (11900, 13)\n",
            "Установленная длина ответов на вход : 13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwsKk9dzNeqI"
      },
      "source": [
        "######################\n",
        "# Раскодированные выходные данные(ответы)\n",
        "######################\n",
        "tokenizedAnswers = tokenizer.texts_to_sequences(answers) # разбиваем текст ответов на последовательности индексов\n",
        "for i in range(len(tokenizedAnswers)) : # для разбитых на последовательности ответов\n",
        "  tokenizedAnswers[i] = tokenizedAnswers[i][1:] # избавляемся от тега <START>\n",
        "# Делаем последовательности одной длины, заполняя нулями более короткие ответы\n",
        "paddedAnswers = pad_sequences(tokenizedAnswers, maxlen=maxLenAnswers , padding='post')\n",
        "\n",
        "oneHotAnswers = utils.to_categorical(paddedAnswers, vocabularySize) # переводим в one hot vector\n",
        "decoderForOutput = np.array(oneHotAnswers) # и сохраняем в виде массива numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRl1k7SVaA6w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80fa3023-4ac6-4d47-f179-971bb127c603"
      },
      "source": [
        "print('Пример раскодированного ответа на вход : {}'.format(decoderForInput[100][:21]))  \n",
        "print('Пример раскодированного ответа на выход : {}'.format(decoderForOutput[100][4][:21])) \n",
        "print('Размеры раскодированного массива ответов на выход : {}'.format(decoderForOutput.shape))\n",
        "print('Установленная длина вопросов на выход : {}'.format(maxLenAnswers)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Пример раскодированного ответа на вход : [    1   673    19    93 10558     2     0     0     0     0     0     0\n",
            "     0]\n",
            "Пример раскодированного ответа на выход : [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Размеры раскодированного массива ответов на выход : (11900, 13, 15104)\n",
            "Установленная длина вопросов на выход : 13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0KR6Mh_hp1f"
      },
      "source": [
        "## **Параметры нейросети и модель обучения**\n",
        "\n",
        "*Разбор данного раздела:* https://youtu.be/LV-ScxAqnMY?t=5531"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSSOhZpgh9LI"
      },
      "source": [
        "######################\n",
        "# Создадим функцию, которая преобразует вопрос пользователя в последовательность индексов\n",
        "######################\n",
        "def strToTokens(sentence: str): # функция принимает строку на вход (предложение с вопросом)\n",
        "  words = sentence.lower().split() # приводит предложение к нижнему регистру и разбирает на слова\n",
        "  tokensList = list() # здесь будет последовательность токенов/индексов\n",
        "  for word in words: # для каждого слова в предложении\n",
        "    tokensList.append(tokenizer.word_index[word]) # определяем токенизатором индекс и добавляем в список\n",
        "\n",
        "    # Функция вернёт вопрос в виде последовательности индексов, ограниченной длиной самого длинного вопроса из нашей базы вопросов\n",
        "  return pad_sequences([tokensList], maxlen=maxLenQuestions , padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kv9utvcjh2co"
      },
      "source": [
        "######################\n",
        "# Создаем рабочую модель для вывода ответов на запросы пользователя\n",
        "######################\n",
        "def makeInferenceModels():\n",
        "  # Определим модель кодера, на входе далее будут закодированные вопросы(encoderForInputs), на выходе состояния state_h, state_c\n",
        "  encoderModel = Model(encoderInputs, encoderStates) \n",
        "\n",
        "  decoderStateInput_h = Input(shape=(200 ,)) # обозначим размерность для входного слоя с состоянием state_h\n",
        "  decoderStateInput_c = Input(shape=(200 ,)) # обозначим размерность для входного слоя с состоянием state_c\n",
        "\n",
        "  decoderStatesInputs = [decoderStateInput_h, decoderStateInput_c] # возьмем оба inputs вместе и запишем в decoderStatesInputs\n",
        "\n",
        "  # Берём ответы, прошедшие через эмбединг, вместе с состояниями и подаём LSTM cлою\n",
        "  decoderOutputs, state_h, state_c = decoderLSTM(decoderEmbedding, initial_state=decoderStatesInputs)\n",
        "  decoderStates = [state_h, state_c] # LSTM даст нам новые состояния\n",
        "  decoderOutputs = decoderDense(decoderOutputs) # и ответы, которые мы пропустим через полносвязный слой с софтмаксом\n",
        "\n",
        "  # Определим модель декодера, на входе далее будут раскодированные ответы (decoderForInputs) и состояния\n",
        "  # на выходе предсказываемый ответ и новые состояния\n",
        "  decoderModel = Model([decoderInputs] + decoderStatesInputs, [decoderOutputs] + decoderStates)\n",
        "\n",
        "  return encoderModel , decoderModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rRKDr4rhXcZ"
      },
      "source": [
        "######################\n",
        "# Первый входной слой, кодер, выходной слой\n",
        "######################\n",
        "encoderInputs = Input(shape=(None , )) # размеры на входе сетки (здесь будет encoderForInput)\n",
        "# Эти данные проходят через слой Embedding (длина словаря, размерность) \n",
        "encoderEmbedding = Embedding(vocabularySize, 200 , mask_zero=True) (encoderInputs)\n",
        "# Затем выход с Embedding пойдёт в LSTM слой, на выходе у которого будет два вектора состояния - state_h , state_c\n",
        "# Вектора состояния - state_h , state_c зададутся в LSTM слое декодера в блоке ниже\n",
        "encoderOutputs, state_h , state_c = LSTM(200, return_state=True)(encoderEmbedding)\n",
        "encoderStates = [state_h, state_c]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_yv8Y6QWX2D"
      },
      "source": [
        "######################\n",
        "# Второй входной слой, декодер, выходной слой\n",
        "######################\n",
        "decoderInputs = Input(shape=(None, )) # размеры на входе сетки (здесь будет decoderForInput)\n",
        "# Эти данные проходят через слой Embedding (длина словаря, размерность) \n",
        "# mask_zero=True - игнорировать нулевые padding при передаче в LSTM. Предотвратит вывод ответа типа: \"У меня все хорошо PAD PAD PAD PAD PAD PAD..\"\n",
        "decoderEmbedding = Embedding(vocabularySize, 200, mask_zero=True) (decoderInputs) \n",
        "# Затем выход с Embedding пойдёт в LSTM слой, которому передаются вектора состояния - state_h , state_c\n",
        "decoderLSTM = LSTM(200, return_state=True, return_sequences=True)\n",
        "decoderOutputs , _ , _ = decoderLSTM (decoderEmbedding, initial_state=encoderStates)\n",
        "# И от LSTM'а сигнал decoderOutputs пропускаем через полносвязный слой с софтмаксом на выходе\n",
        "decoderDense = Dense(vocabularySize, activation='softmax') \n",
        "output = decoderDense (decoderOutputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYnTen_UWc5F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 891
        },
        "outputId": "70e56b85-0489-4145-8d2a-011c500ab67e"
      },
      "source": [
        "######################\n",
        "# Собираем тренировочную модель нейросети\n",
        "######################\n",
        "model = Model([encoderInputs, decoderInputs], output)\n",
        "model.compile(optimizer=RMSprop(), loss='categorical_crossentropy')\n",
        "\n",
        "print(model.summary()) # выведем на экран информацию о построенной модели нейросети\n",
        "plot_model(model, to_file='model.png') # и построим график для визуализации слоев и связей между ними"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 200)    3020800     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 200)    3020800     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 200), (None, 320800      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 200),  320800      embedding_1[0][0]                \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 15104)  3035904     lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 9,719,104\n",
            "Trainable params: 9,719,104\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CT2b_XMozVJu"
      },
      "source": [
        "## 20 epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbelEm0zhadD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52f24538-be5d-454e-a48e-dccff8ed06ea"
      },
      "source": [
        "# Запустим обучение и сохраним модель\n",
        "model.fit([encoderForInput , decoderForInput], decoderForOutput, batch_size=50, epochs=20) \n",
        "# model.save( '/content/drive/My Drive/Предобученные сети/model_30epochs(rms).h5' )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "238/238 [==============================] - 10s 43ms/step - loss: 2.2202\n",
            "Epoch 2/20\n",
            "238/238 [==============================] - 10s 43ms/step - loss: 1.9783\n",
            "Epoch 3/20\n",
            "238/238 [==============================] - 10s 43ms/step - loss: 1.9311\n",
            "Epoch 4/20\n",
            "238/238 [==============================] - 10s 43ms/step - loss: 1.8902\n",
            "Epoch 5/20\n",
            "238/238 [==============================] - 10s 43ms/step - loss: 1.8546\n",
            "Epoch 6/20\n",
            "238/238 [==============================] - 10s 42ms/step - loss: 1.8193\n",
            "Epoch 7/20\n",
            "238/238 [==============================] - 10s 43ms/step - loss: 1.7852\n",
            "Epoch 8/20\n",
            "238/238 [==============================] - 10s 43ms/step - loss: 1.7526\n",
            "Epoch 9/20\n",
            "238/238 [==============================] - 10s 42ms/step - loss: 1.7184\n",
            "Epoch 10/20\n",
            "238/238 [==============================] - 10s 43ms/step - loss: 1.6852\n",
            "Epoch 11/20\n",
            "238/238 [==============================] - 10s 43ms/step - loss: 1.6510\n",
            "Epoch 12/20\n",
            "238/238 [==============================] - 10s 43ms/step - loss: 1.6148\n",
            "Epoch 13/20\n",
            "238/238 [==============================] - 10s 42ms/step - loss: 1.5799\n",
            "Epoch 14/20\n",
            "238/238 [==============================] - 10s 43ms/step - loss: 1.5473\n",
            "Epoch 15/20\n",
            "238/238 [==============================] - 10s 43ms/step - loss: 1.5128\n",
            "Epoch 16/20\n",
            "238/238 [==============================] - 10s 43ms/step - loss: 1.4790\n",
            "Epoch 17/20\n",
            "238/238 [==============================] - 10s 43ms/step - loss: 1.4465\n",
            "Epoch 18/20\n",
            "238/238 [==============================] - 10s 42ms/step - loss: 1.4145\n",
            "Epoch 19/20\n",
            "238/238 [==============================] - 10s 42ms/step - loss: 1.3818\n",
            "Epoch 20/20\n",
            "238/238 [==============================] - 10s 42ms/step - loss: 1.3484\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f39fcde2048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgmdPm78Hfo_"
      },
      "source": [
        "# обернем общение с сетью в функцию, чтобы не копировать этот текст постоянно\n",
        "def start_chat(num_steps=3):\n",
        "  encModel , decModel = makeInferenceModels() # запускаем функцию для построения модели кодера и декодера\n",
        "\n",
        "  for _ in range(num_steps): # задаем количество вопросов, и на каждой итерации в этом диапазоне:\n",
        "    # Получаем значения состояний, которые определит кодер в соответствии с заданным вопросом\n",
        "    statesValues = encModel.predict(strToTokens(input( 'Задайте вопрос : ' )))\n",
        "    # Создаём пустой массив размером (1, 1)\n",
        "    emptyTargetSeq = np.zeros((1, 1))    \n",
        "    emptyTargetSeq[0, 0] = tokenizer.word_index['start'] # положим в пустую последовательность начальное слово 'start' в виде индекса\n",
        "\n",
        "    stopCondition = False # зададим условие, при срабатывании которого, прекратится генерация очередного слова\n",
        "    decodedTranslation = '' # здесь будет собираться генерируемый ответ\n",
        "    while not stopCondition : # пока не сработало стоп-условие\n",
        "      # В модель декодера подадим пустую последовательность со словом 'start' и состояния предсказанные кодером по заданному вопросу.\n",
        "      # декодер заменит слово 'start' предсказанным сгенерированным словом и обновит состояния\n",
        "      decOutputs , h , c = decModel.predict([emptyTargetSeq] + statesValues)\n",
        "      \n",
        "      #argmax пробежит по вектору decOutputs'а[0,0,15104], найдет макс.значение, и вернёт нам номер индекса под которым оно лежит в массиве\n",
        "      sampledWordIndex = np.argmax( decOutputs[0, 0, :]) # argmax возьмем от оси, в которой 15104 элементов. Получили индекс предсказанного слова.\n",
        "      sampledWord = None # создаем переменную, в которую положим слово, преобразованное на естественный язык\n",
        "      for word , index in tokenizer.word_index.items():\n",
        "        if sampledWordIndex == index: # если индекс выбранного слова соответствует какому-то индексу из словаря\n",
        "          decodedTranslation += ' {}'.format(word) # слово, идущее под этим индексом в словаре, добавляется в итоговый ответ \n",
        "          sampledWord = word # выбранное слово фиксируем в переменную sampledWord\n",
        "      \n",
        "      # Если выбранным словом оказывается 'end' либо если сгенерированный ответ превышает заданную максимальную длину ответа\n",
        "      if sampledWord == 'end' or len(decodedTranslation.split()) > maxLenAnswers:\n",
        "        stopCondition = True # то срабатывает стоп-условие и прекращаем генерацию\n",
        "\n",
        "      emptyTargetSeq = np.zeros((1, 1)) # создаем пустой массив\n",
        "      emptyTargetSeq[0, 0] = sampledWordIndex # заносим туда индекс выбранного слова\n",
        "      statesValues = [h, c] # и состояния, обновленные декодером\n",
        "      # и продолжаем цикл с обновленными параметрами\n",
        "    \n",
        "    print(decodedTranslation[:-3]) # выводим ответ сгенерированный декодером"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ0Dxd1eiEid",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f86200f0-68ea-49ed-d8a5-7717bbc1f2d5"
      },
      "source": [
        "start_chat()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Задайте вопрос : хочешь есть\n",
            " нет \n",
            "Задайте вопрос : почему сегодня тепло\n",
            " не знаю \n",
            "Задайте вопрос : как нужно отвечать\n",
            " все нормально \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-HVZP695cc7"
      },
      "source": [
        "## +30 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74iVgXmP5XmC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "301139e7-fd8d-416c-8b37-cc67ac919090"
      },
      "source": [
        "# Запустим обучение и сохраним модель\n",
        "model.fit([encoderForInput , decoderForInput], decoderForOutput, batch_size=50, epochs=30) \n",
        "# model.save( '/content/drive/My Drive/Предобученные сети/model_30epochs(rms).h5' )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 1.3482\n",
            "Epoch 2/30\n",
            "238/238 [==============================] - 10s 40ms/step - loss: 1.3191\n",
            "Epoch 3/30\n",
            "238/238 [==============================] - 10s 40ms/step - loss: 1.2918\n",
            "Epoch 4/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 1.2646\n",
            "Epoch 5/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 1.2370\n",
            "Epoch 6/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 1.2104\n",
            "Epoch 7/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 1.1864\n",
            "Epoch 8/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 1.1634\n",
            "Epoch 9/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 1.1415\n",
            "Epoch 10/30\n",
            "238/238 [==============================] - 10s 40ms/step - loss: 1.1211\n",
            "Epoch 11/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 1.1019\n",
            "Epoch 12/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 1.0848\n",
            "Epoch 13/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 1.0672\n",
            "Epoch 14/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 1.0515\n",
            "Epoch 15/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 1.0352\n",
            "Epoch 16/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 1.0208\n",
            "Epoch 17/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 1.0053\n",
            "Epoch 18/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.9904\n",
            "Epoch 19/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.9754\n",
            "Epoch 20/30\n",
            "238/238 [==============================] - 10s 42ms/step - loss: 0.9597\n",
            "Epoch 21/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.9405\n",
            "Epoch 22/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.9257\n",
            "Epoch 23/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.9131\n",
            "Epoch 24/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.9008\n",
            "Epoch 25/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.8921\n",
            "Epoch 26/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.8846\n",
            "Epoch 27/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.8782\n",
            "Epoch 28/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.8728\n",
            "Epoch 29/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.8674\n",
            "Epoch 30/30\n",
            "238/238 [==============================] - 10s 40ms/step - loss: 0.8636\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd02ea56cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDnIr_T5557a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5a8668c-9e95-41dd-e188-aa02c51a28fe"
      },
      "source": [
        "start_chat()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Задайте вопрос : хочешь есть\n",
            " есть \n",
            "Задайте вопрос : почему сегодня тепло\n",
            " не думаю \n",
            "Задайте вопрос : как нужно отвечать\n",
            " ты его уверен \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IevPf_F76727"
      },
      "source": [
        "## +50 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3NbIgNm63dx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d115953-6f50-4dce-8ffc-a7db861e02ea"
      },
      "source": [
        "# Запустим обучение и сохраним модель\n",
        "model.fit([encoderForInput , decoderForInput], decoderForOutput, batch_size=50, epochs=50) \n",
        "# model.save( '/content/drive/My Drive/Предобученные сети/model_30epochs(rms).h5' )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.8590\n",
            "Epoch 2/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.8559\n",
            "Epoch 3/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.8524\n",
            "Epoch 4/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.8485\n",
            "Epoch 5/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.8453\n",
            "Epoch 6/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.8414\n",
            "Epoch 7/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.8388\n",
            "Epoch 8/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.8352\n",
            "Epoch 9/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.8320\n",
            "Epoch 10/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.8289\n",
            "Epoch 11/50\n",
            "238/238 [==============================] - 10s 42ms/step - loss: 0.8259\n",
            "Epoch 12/50\n",
            "238/238 [==============================] - 10s 42ms/step - loss: 0.8235\n",
            "Epoch 13/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.8202\n",
            "Epoch 14/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.8176\n",
            "Epoch 15/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.8152\n",
            "Epoch 16/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.8135\n",
            "Epoch 17/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.8121\n",
            "Epoch 18/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.8100\n",
            "Epoch 19/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.8094\n",
            "Epoch 20/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.8079\n",
            "Epoch 21/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.8063\n",
            "Epoch 22/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.8056\n",
            "Epoch 23/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.8045\n",
            "Epoch 24/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.8028\n",
            "Epoch 25/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.8018\n",
            "Epoch 26/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.8008\n",
            "Epoch 27/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.7999\n",
            "Epoch 28/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.7984\n",
            "Epoch 29/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.7980\n",
            "Epoch 30/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.7971\n",
            "Epoch 31/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.7951\n",
            "Epoch 32/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.7942\n",
            "Epoch 33/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.7933\n",
            "Epoch 34/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.7912\n",
            "Epoch 35/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.7903\n",
            "Epoch 36/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.7887\n",
            "Epoch 37/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.7877\n",
            "Epoch 38/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.7859\n",
            "Epoch 39/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.7851\n",
            "Epoch 40/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.7835\n",
            "Epoch 41/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.7826\n",
            "Epoch 42/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.7810\n",
            "Epoch 43/50\n",
            "238/238 [==============================] - 10s 42ms/step - loss: 0.7799\n",
            "Epoch 44/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.7786\n",
            "Epoch 45/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.7776\n",
            "Epoch 46/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.7757\n",
            "Epoch 47/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.7739\n",
            "Epoch 48/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.7736\n",
            "Epoch 49/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.7722\n",
            "Epoch 50/50\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 0.7715\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd030a22e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blhVoaiw7Ap2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1560ea9-4373-4001-c599-085dfafd4c74"
      },
      "source": [
        "start_chat()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Задайте вопрос : хочешь есть\n",
            " давай \n",
            "Задайте вопрос : почему сегодня тепло\n",
            " не думаю \n",
            "Задайте вопрос : как нужно отвечать\n",
            " ты и что случилось \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rn6HA6EZRxE8"
      },
      "source": [
        "## Выводы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnaNJ3RWRzP-"
      },
      "source": [
        "Может так случайно вышло, но на первых 20 эпохах ответы получились более адекватными. Однако, думаю, что это случайность. И так как ошибка продолжает снижаться, то необходимо дальнейшее обучение. Видно, что с обучением сеть пытается ответить большим количеством слов, а не односложными ответами как в начале обучения.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1O3eMIXCpnl"
      },
      "source": [
        "# Pro - 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fw0qctUPe6p"
      },
      "source": [
        "Пункт первый задания по распознанию слов, на которых сеть не обучалась, встроил сразу в определение токенайзера, а также в функцию перевода вопроса в индексы (использовал text_to_sequences вместо word_index). Получается, что все незнакомые слова сеть интерпретирует как unkonown с индексом 1\n",
        "\n",
        "Второй пункт разбил на две части: сначала оставил знаки препинания \"как есть\", то есть вместе со словами. Таким образом при разбивке токенайзером слово со знаком препинания воспринималось как другое слово. Таким образом сильно расширился словарь слов. А при встрече известного слова, но ссо знаком препинания, с которым в тексте оно не стречалось,это слово интерпретировалось как unknown.\n",
        "\n",
        "Потом перед токенизированием я добавил пробелы перед каждым знаком препинания, чтобы токенайзер воспринимал каждый знак препинания как отдельное слово и давал ему свой индекс. Словарь при этом увеличился, но не так сильно как в предыдущем пункте, но увеличился максимальный размер ответа и вопроса. \n",
        "\n",
        "На мой взгляд добавление знаков ухудшило сеть. При этом токенизация знаков препинания как отдельного слово дает лучше результаты."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0We58YNGhgx"
      },
      "source": [
        "## Знаки препинания вместе со словами"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qj0mlypHGk9E"
      },
      "source": [
        "\n",
        "tokenizer = Tokenizer(filters='\"#$%&()*+/<=>@[\\\\]^_`{|}~\\t\\n', oov_token='unknown', char_level=False, split=' ')\n",
        "\n",
        "tokenizer.fit_on_texts(questions + answers) # загружаем в токенизатор список вопросов-ответов для сборки словаря частотности\n",
        "vocabularyItems = list(tokenizer.word_index.items()) # список с cодержимым словаря\n",
        "\n",
        "vocabularySize = len(vocabularyItems)+1 # размер словаря\n",
        "del vocabularyItems\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auL3vkKMGk9F",
        "outputId": "530542a3-7342-4911-c567-966bb7432944"
      },
      "source": [
        "######################\n",
        "# Устанавливаем закодированные входные данные(вопросы)\n",
        "######################\n",
        "tokenizedQuestions = tokenizer.texts_to_sequences(questions) # разбиваем текст вопросов на последовательности индексов\n",
        "maxLenQuestions = max([ len(x) for x in tokenizedQuestions]) # уточняем длину самого большого вопроса\n",
        "# Делаем последовательности одной длины, заполняя нулями более короткие вопросы\n",
        "paddedQuestions = pad_sequences(tokenizedQuestions, maxlen=maxLenQuestions, padding='post')\n",
        "\n",
        "# Предподготавливаем данные для входа в сеть\n",
        "encoderForInput = np.array(paddedQuestions) # переводим в numpy массив\n",
        "print('Пример оригинального вопроса на вход : {}'.format(questions[100])) \n",
        "print('Пример кодированного вопроса на вход : {}'.format(encoderForInput[100])) \n",
        "print('Размеры закодированного массива вопросов на вход : {}'.format(encoderForInput.shape)) \n",
        "print('Установленная длина вопросов на вход : {}'.format(maxLenQuestions)) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Пример оригинального вопроса на вход : Какая же мораль?\n",
            "Пример кодированного вопроса на вход : [ 201   17 6500    0    0    0    0    0    0    0    0]\n",
            "Размеры закодированного массива вопросов на вход : (11900, 11)\n",
            "Установленная длина вопросов на вход : 11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U59vBeP3Gk9J",
        "outputId": "6ad3a900-c364-46bd-f047-a5a0c54cea14"
      },
      "source": [
        "######################\n",
        "# Устанавливаем раскодированные входные данные(ответы)\n",
        "######################\n",
        "tokenizedAnswers = tokenizer.texts_to_sequences(answers) # разбиваем текст ответов на последовательности индексов\n",
        "maxLenAnswers = max([len(x) for x in tokenizedAnswers]) # уточняем длину самого большого ответа\n",
        "# Делаем последовательности одной длины, заполняя нулями более короткие ответы\n",
        "paddedAnswers = pad_sequences(tokenizedAnswers, maxlen=maxLenAnswers, padding='post')\n",
        "\n",
        "# Предподготавливаем данные для входа в сеть\n",
        "decoderForInput = np.array(paddedAnswers) # переводим в numpy массив\n",
        "print('Пример оригинального ответа на вход: {}'.format(answers[100])) \n",
        "print('Пример раскодированного ответа на вход : {}'.format(decoderForInput[100][:30])) \n",
        "print('Размеры раскодированного массива ответов на вход : {}'.format(decoderForInput.shape)) \n",
        "print('Установленная длина ответов на вход : {}'.format(maxLenAnswers)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Пример оригинального ответа на вход: <START> Никакой. Так просто вспомнилось. <END>\n",
            "Пример раскодированного ответа на вход : [    2 14660    21    96 14661     3     0     0     0     0     0     0\n",
            "     0]\n",
            "Размеры раскодированного массива ответов на вход : (11900, 13)\n",
            "Установленная длина ответов на вход : 13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYvtziCjGk9K"
      },
      "source": [
        "######################\n",
        "# Раскодированные выходные данные(ответы)\n",
        "######################\n",
        "tokenizedAnswers = tokenizer.texts_to_sequences(answers) # разбиваем текст ответов на последовательности индексов\n",
        "for i in range(len(tokenizedAnswers)) : # для разбитых на последовательности ответов\n",
        "  tokenizedAnswers[i] = tokenizedAnswers[i][1:] # избавляемся от тега <START>\n",
        "# Делаем последовательности одной длины, заполняя нулями более короткие ответы\n",
        "paddedAnswers = pad_sequences(tokenizedAnswers, maxlen=maxLenAnswers , padding='post')\n",
        "\n",
        "decoderForOutput = utils.to_categorical(paddedAnswers, vocabularySize) # переводим в one hot vector\n",
        "# decoderForOutput = np.array(oneHotAnswers) # и сохраняем в виде массива numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xkr_smqGk9K",
        "outputId": "3234b81a-c45b-4815-bc1b-7eaf0eb15d6c"
      },
      "source": [
        "type(decoderForOutput)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xUiBFUqGk9L",
        "outputId": "60c1b562-265e-446c-8b5f-508a971a777c"
      },
      "source": [
        "print('Пример раскодированного ответа на вход : {}'.format(decoderForInput[100][:21]))  \n",
        "print('Пример раскодированного ответа на выход : {}'.format(decoderForOutput[100][4][:21])) \n",
        "print('Размеры раскодированного массива ответов на выход : {}'.format(decoderForOutput.shape))\n",
        "print('Установленная длина вопросов на выход : {}'.format(maxLenAnswers)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Пример раскодированного ответа на вход : [    2 14660    21    96 14661     3     0     0     0     0     0     0\n",
            "     0]\n",
            "Пример раскодированного ответа на выход : [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Размеры раскодированного массива ответов на выход : (11900, 13, 22342)\n",
            "Установленная длина вопросов на выход : 13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KxEfz45Gk9L"
      },
      "source": [
        "######################\n",
        "# Создадим функцию, которая преобразует вопрос пользователя в последовательность индексов\n",
        "######################\n",
        "def strToTokens(sentence: str): # функция принимает строку на вход (предложение с вопросом)\n",
        "  words = sentence.lower().split() # приводит предложение к нижнему регистру и разбирает на слова\n",
        "  tokensList = list() # здесь будет последовательность токенов/индексов\n",
        "  for word in words: # для каждого слова в предложении\n",
        "    tokensList.append(tokenizer.texts_to_sequences([word])[0][0])   # изменено для неизвестных словарю слов\n",
        "    # tokensList.append(tokenizer.word_index[word]) # определяем токенизатором индекс и добавляем в список\n",
        "\n",
        "    # Функция вернёт вопрос в виде последовательности индексов, ограниченной длиной самого длинного вопроса из нашей базы вопросов\n",
        "  return pad_sequences([tokensList], maxlen=maxLenQuestions , padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f24uM8mhGk9M"
      },
      "source": [
        "######################\n",
        "# Создаем рабочую модель для вывода ответов на запросы пользователя\n",
        "######################\n",
        "def makeInferenceModels():\n",
        "  # Определим модель кодера, на входе далее будут закодированные вопросы(encoderForInputs), на выходе состояния state_h, state_c\n",
        "  encoderModel = Model(encoderInputs, encoderStates) \n",
        "\n",
        "  decoderStateInput_h = Input(shape=(200 ,)) # обозначим размерность для входного слоя с состоянием state_h\n",
        "  decoderStateInput_c = Input(shape=(200 ,)) # обозначим размерность для входного слоя с состоянием state_c\n",
        "\n",
        "  decoderStatesInputs = [decoderStateInput_h, decoderStateInput_c] # возьмем оба inputs вместе и запишем в decoderStatesInputs\n",
        "\n",
        "  # Берём ответы, прошедшие через эмбединг, вместе с состояниями и подаём LSTM cлою\n",
        "  decoderOutputs, state_h, state_c = decoderLSTM(decoderEmbedding, initial_state=decoderStatesInputs)\n",
        "  decoderStates = [state_h, state_c] # LSTM даст нам новые состояния\n",
        "  decoderOutputs = decoderDense(decoderOutputs) # и ответы, которые мы пропустим через полносвязный слой с софтмаксом\n",
        "\n",
        "  # Определим модель декодера, на входе далее будут раскодированные ответы (decoderForInputs) и состояния\n",
        "  # на выходе предсказываемый ответ и новые состояния\n",
        "  decoderModel = Model([decoderInputs] + decoderStatesInputs, [decoderOutputs] + decoderStates)\n",
        "\n",
        "  return encoderModel , decoderModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8hqrJduGk9M"
      },
      "source": [
        "######################\n",
        "# Первый входной слой, кодер, выходной слой\n",
        "######################\n",
        "encoderInputs = Input(shape=(None , )) # размеры на входе сетки (здесь будет encoderForInput)\n",
        "# Эти данные проходят через слой Embedding (длина словаря, размерность) \n",
        "encoderEmbedding = Embedding(vocabularySize, 200 , mask_zero=True) (encoderInputs)\n",
        "# Затем выход с Embedding пойдёт в LSTM слой, на выходе у которого будет два вектора состояния - state_h , state_c\n",
        "# Вектора состояния - state_h , state_c зададутся в LSTM слое декодера в блоке ниже\n",
        "encoderOutputs, state_h , state_c = LSTM(200, return_state=True)(encoderEmbedding)\n",
        "encoderStates = [state_h, state_c]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxEPG-fqGk9M"
      },
      "source": [
        "######################\n",
        "# Второй входной слой, декодер, выходной слой\n",
        "######################\n",
        "decoderInputs = Input(shape=(None, )) # размеры на входе сетки (здесь будет decoderForInput)\n",
        "# Эти данные проходят через слой Embedding (длина словаря, размерность) \n",
        "# mask_zero=True - игнорировать нулевые padding при передаче в LSTM. Предотвратит вывод ответа типа: \"У меня все хорошо PAD PAD PAD PAD PAD PAD..\"\n",
        "decoderEmbedding = Embedding(vocabularySize, 200, mask_zero=True) (decoderInputs) \n",
        "# Затем выход с Embedding пойдёт в LSTM слой, которому передаются вектора состояния - state_h , state_c\n",
        "decoderLSTM = LSTM(200, return_state=True, return_sequences=True)\n",
        "decoderOutputs , _ , _ = decoderLSTM (decoderEmbedding, initial_state=encoderStates)\n",
        "# И от LSTM'а сигнал decoderOutputs пропускаем через полносвязный слой с софтмаксом на выходе\n",
        "decoderDense = Dense(vocabularySize, activation='softmax') \n",
        "output = decoderDense (decoderOutputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 891
        },
        "id": "taVeFtYsGk9M",
        "outputId": "76321bd3-e4d2-4a37-cde1-fc02a1ee7c2e"
      },
      "source": [
        "######################\n",
        "# Собираем тренировочную модель нейросети\n",
        "######################\n",
        "model = Model([encoderInputs, decoderInputs], output)\n",
        "model.compile(optimizer=RMSprop(), loss='categorical_crossentropy')\n",
        "\n",
        "print(model.summary()) # выведем на экран информацию о построенной модели нейросети\n",
        "plot_model(model, to_file='model.png') # и построим график для визуализации слоев и связей между ними"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 200)    4468400     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 200)    4468400     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 200), (None, 320800      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 200),  320800      embedding_1[0][0]                \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 22342)  4490742     lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 14,069,142\n",
            "Trainable params: 14,069,142\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaNnMtg2Gk9M",
        "outputId": "d1a93a92-7ce8-4a25-df00-54ae94bed357"
      },
      "source": [
        "# Запустим обучение и сохраним модель\n",
        "model.fit([encoderForInput , decoderForInput], decoderForOutput, batch_size=50, epochs=400) \n",
        "# model.save( '/content/drive/MyDrive/26 Генерация текста/saved-0.h5' )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "238/238 [==============================] - 14s 59ms/step - loss: 2.3900\n",
            "Epoch 2/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 2.0959\n",
            "Epoch 3/400\n",
            "238/238 [==============================] - 14s 59ms/step - loss: 2.0196\n",
            "Epoch 4/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.9706\n",
            "Epoch 5/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.9323\n",
            "Epoch 6/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.8971\n",
            "Epoch 7/400\n",
            "238/238 [==============================] - 14s 57ms/step - loss: 1.8617\n",
            "Epoch 8/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.8253\n",
            "Epoch 9/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.7904\n",
            "Epoch 10/400\n",
            "238/238 [==============================] - 14s 57ms/step - loss: 1.7536\n",
            "Epoch 11/400\n",
            "238/238 [==============================] - 14s 57ms/step - loss: 1.7164\n",
            "Epoch 12/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.6797\n",
            "Epoch 13/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.6429\n",
            "Epoch 14/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.6105\n",
            "Epoch 15/400\n",
            "238/238 [==============================] - 14s 59ms/step - loss: 1.5787\n",
            "Epoch 16/400\n",
            "238/238 [==============================] - 14s 57ms/step - loss: 1.5480\n",
            "Epoch 17/400\n",
            "238/238 [==============================] - 14s 57ms/step - loss: 1.5219\n",
            "Epoch 18/400\n",
            "238/238 [==============================] - 14s 57ms/step - loss: 1.4948\n",
            "Epoch 19/400\n",
            "238/238 [==============================] - 14s 57ms/step - loss: 1.4689\n",
            "Epoch 20/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.4433\n",
            "Epoch 21/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.4166\n",
            "Epoch 22/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.3941\n",
            "Epoch 23/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.3682\n",
            "Epoch 24/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.3441\n",
            "Epoch 25/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.3193\n",
            "Epoch 26/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.2892\n",
            "Epoch 27/400\n",
            "238/238 [==============================] - 14s 57ms/step - loss: 1.2662\n",
            "Epoch 28/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.2432\n",
            "Epoch 29/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.2196\n",
            "Epoch 30/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.2023\n",
            "Epoch 31/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.1853\n",
            "Epoch 32/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.1689\n",
            "Epoch 33/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.1519\n",
            "Epoch 34/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.1371\n",
            "Epoch 35/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.1275\n",
            "Epoch 36/400\n",
            "238/238 [==============================] - 14s 57ms/step - loss: 1.1187\n",
            "Epoch 37/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.1128\n",
            "Epoch 38/400\n",
            "238/238 [==============================] - 14s 59ms/step - loss: 1.1076\n",
            "Epoch 39/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.1015\n",
            "Epoch 40/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.0955\n",
            "Epoch 41/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.0893\n",
            "Epoch 42/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.0856\n",
            "Epoch 43/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.0824\n",
            "Epoch 44/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.0788\n",
            "Epoch 45/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.0762\n",
            "Epoch 46/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.0722\n",
            "Epoch 47/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.0688\n",
            "Epoch 48/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.0653\n",
            "Epoch 49/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.0618\n",
            "Epoch 50/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.0572\n",
            "Epoch 51/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.0530\n",
            "Epoch 52/400\n",
            "238/238 [==============================] - 14s 57ms/step - loss: 1.0478\n",
            "Epoch 53/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.0431\n",
            "Epoch 54/400\n",
            "238/238 [==============================] - 14s 57ms/step - loss: 1.0391\n",
            "Epoch 55/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.0362\n",
            "Epoch 56/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.0341\n",
            "Epoch 57/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.0324\n",
            "Epoch 58/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.0310\n",
            "Epoch 59/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.0305\n",
            "Epoch 60/400\n",
            "238/238 [==============================] - 14s 59ms/step - loss: 1.0286\n",
            "Epoch 61/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.0271\n",
            "Epoch 62/400\n",
            "238/238 [==============================] - 14s 57ms/step - loss: 1.0256\n",
            "Epoch 63/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.0235\n",
            "Epoch 64/400\n",
            "238/238 [==============================] - 14s 57ms/step - loss: 1.0210\n",
            "Epoch 65/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.0194\n",
            "Epoch 66/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.0186\n",
            "Epoch 67/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.0175\n",
            "Epoch 68/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.0154\n",
            "Epoch 69/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.0129\n",
            "Epoch 70/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.0118\n",
            "Epoch 71/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.0100\n",
            "Epoch 72/400\n",
            "238/238 [==============================] - 14s 57ms/step - loss: 1.0085\n",
            "Epoch 73/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.0062\n",
            "Epoch 74/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.0052\n",
            "Epoch 75/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.0034\n",
            "Epoch 76/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.0023\n",
            "Epoch 77/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 1.0009\n",
            "Epoch 78/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9999\n",
            "Epoch 79/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9982\n",
            "Epoch 80/400\n",
            "238/238 [==============================] - 14s 57ms/step - loss: 0.9963\n",
            "Epoch 81/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9967\n",
            "Epoch 82/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9956\n",
            "Epoch 83/400\n",
            "238/238 [==============================] - 14s 59ms/step - loss: 0.9939\n",
            "Epoch 84/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9933\n",
            "Epoch 85/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9924\n",
            "Epoch 86/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9920\n",
            "Epoch 87/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9914\n",
            "Epoch 88/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9911\n",
            "Epoch 89/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9909\n",
            "Epoch 90/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9904\n",
            "Epoch 91/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9911\n",
            "Epoch 92/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9916\n",
            "Epoch 93/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9915\n",
            "Epoch 94/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9916\n",
            "Epoch 95/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9922\n",
            "Epoch 96/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9920\n",
            "Epoch 97/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9921\n",
            "Epoch 98/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9925\n",
            "Epoch 99/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9922\n",
            "Epoch 100/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9920\n",
            "Epoch 101/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9916\n",
            "Epoch 102/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9913\n",
            "Epoch 103/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9907\n",
            "Epoch 104/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9891\n",
            "Epoch 105/400\n",
            "238/238 [==============================] - 14s 59ms/step - loss: 0.9878\n",
            "Epoch 106/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9867\n",
            "Epoch 107/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9865\n",
            "Epoch 108/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9860\n",
            "Epoch 109/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9859\n",
            "Epoch 110/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9862\n",
            "Epoch 111/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9856\n",
            "Epoch 112/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9852\n",
            "Epoch 113/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9852\n",
            "Epoch 114/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9848\n",
            "Epoch 115/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9848\n",
            "Epoch 116/400\n",
            "238/238 [==============================] - 14s 57ms/step - loss: 0.9840\n",
            "Epoch 117/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9836\n",
            "Epoch 118/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9824\n",
            "Epoch 119/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9820\n",
            "Epoch 120/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9814\n",
            "Epoch 121/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9810\n",
            "Epoch 122/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9806\n",
            "Epoch 123/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9793\n",
            "Epoch 124/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9791\n",
            "Epoch 125/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9789\n",
            "Epoch 126/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9775\n",
            "Epoch 127/400\n",
            "238/238 [==============================] - 14s 59ms/step - loss: 0.9772\n",
            "Epoch 128/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9765\n",
            "Epoch 129/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9761\n",
            "Epoch 130/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9749\n",
            "Epoch 131/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9746\n",
            "Epoch 132/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9742\n",
            "Epoch 133/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9731\n",
            "Epoch 134/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9727\n",
            "Epoch 135/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9720\n",
            "Epoch 136/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9715\n",
            "Epoch 137/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9710\n",
            "Epoch 138/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9710\n",
            "Epoch 139/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9706\n",
            "Epoch 140/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9705\n",
            "Epoch 141/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9705\n",
            "Epoch 142/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9707\n",
            "Epoch 143/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9703\n",
            "Epoch 144/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9702\n",
            "Epoch 145/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9703\n",
            "Epoch 146/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9705\n",
            "Epoch 147/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9701\n",
            "Epoch 148/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9695\n",
            "Epoch 149/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9702\n",
            "Epoch 150/400\n",
            "238/238 [==============================] - 14s 59ms/step - loss: 0.9704\n",
            "Epoch 151/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9699\n",
            "Epoch 152/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9704\n",
            "Epoch 153/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9706\n",
            "Epoch 154/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9714\n",
            "Epoch 155/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9710\n",
            "Epoch 156/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9715\n",
            "Epoch 157/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9717\n",
            "Epoch 158/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9717\n",
            "Epoch 159/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9713\n",
            "Epoch 160/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9715\n",
            "Epoch 161/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9716\n",
            "Epoch 162/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9712\n",
            "Epoch 163/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9708\n",
            "Epoch 164/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9705\n",
            "Epoch 165/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9706\n",
            "Epoch 166/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9706\n",
            "Epoch 167/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9701\n",
            "Epoch 168/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9702\n",
            "Epoch 169/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9697\n",
            "Epoch 170/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9691\n",
            "Epoch 171/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9688\n",
            "Epoch 172/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9688\n",
            "Epoch 173/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9688\n",
            "Epoch 174/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9679\n",
            "Epoch 175/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9675\n",
            "Epoch 176/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9677\n",
            "Epoch 177/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9672\n",
            "Epoch 178/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9663\n",
            "Epoch 179/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9658\n",
            "Epoch 180/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9656\n",
            "Epoch 181/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9652\n",
            "Epoch 182/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9655\n",
            "Epoch 183/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9650\n",
            "Epoch 184/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9648\n",
            "Epoch 185/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9642\n",
            "Epoch 186/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9635\n",
            "Epoch 187/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9638\n",
            "Epoch 188/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9636\n",
            "Epoch 189/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9635\n",
            "Epoch 190/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9632\n",
            "Epoch 191/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9626\n",
            "Epoch 192/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9620\n",
            "Epoch 193/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9613\n",
            "Epoch 194/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9616\n",
            "Epoch 195/400\n",
            "238/238 [==============================] - 14s 59ms/step - loss: 0.9609\n",
            "Epoch 196/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9620\n",
            "Epoch 197/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9609\n",
            "Epoch 198/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9601\n",
            "Epoch 199/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9604\n",
            "Epoch 200/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9603\n",
            "Epoch 201/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9589\n",
            "Epoch 202/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9591\n",
            "Epoch 203/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9589\n",
            "Epoch 204/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9585\n",
            "Epoch 205/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9581\n",
            "Epoch 206/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9584\n",
            "Epoch 207/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9583\n",
            "Epoch 208/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9573\n",
            "Epoch 209/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9578\n",
            "Epoch 210/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9575\n",
            "Epoch 211/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9567\n",
            "Epoch 212/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9572\n",
            "Epoch 213/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9566\n",
            "Epoch 214/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9566\n",
            "Epoch 215/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9555\n",
            "Epoch 216/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9550\n",
            "Epoch 217/400\n",
            "238/238 [==============================] - 14s 59ms/step - loss: 0.9548\n",
            "Epoch 218/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9556\n",
            "Epoch 219/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9549\n",
            "Epoch 220/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9538\n",
            "Epoch 221/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9544\n",
            "Epoch 222/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9546\n",
            "Epoch 223/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9533\n",
            "Epoch 224/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9528\n",
            "Epoch 225/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9523\n",
            "Epoch 226/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9520\n",
            "Epoch 227/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9518\n",
            "Epoch 228/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9522\n",
            "Epoch 229/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9522\n",
            "Epoch 230/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9528\n",
            "Epoch 231/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9519\n",
            "Epoch 232/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9515\n",
            "Epoch 233/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9509\n",
            "Epoch 234/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9515\n",
            "Epoch 235/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9505\n",
            "Epoch 236/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9501\n",
            "Epoch 237/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9501\n",
            "Epoch 238/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9488\n",
            "Epoch 239/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9495\n",
            "Epoch 240/400\n",
            "238/238 [==============================] - 14s 59ms/step - loss: 0.9493\n",
            "Epoch 241/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9487\n",
            "Epoch 242/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9493\n",
            "Epoch 243/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9490\n",
            "Epoch 244/400\n",
            "238/238 [==============================] - 14s 59ms/step - loss: 0.9491\n",
            "Epoch 245/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9492\n",
            "Epoch 246/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9483\n",
            "Epoch 247/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9478\n",
            "Epoch 248/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9478\n",
            "Epoch 249/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9478\n",
            "Epoch 250/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9472\n",
            "Epoch 251/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9473\n",
            "Epoch 252/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9475\n",
            "Epoch 253/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9467\n",
            "Epoch 254/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9471\n",
            "Epoch 255/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9465\n",
            "Epoch 256/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9468\n",
            "Epoch 257/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9469\n",
            "Epoch 258/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9474\n",
            "Epoch 259/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9465\n",
            "Epoch 260/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9459\n",
            "Epoch 261/400\n",
            "238/238 [==============================] - 14s 58ms/step - loss: 0.9457\n",
            "Epoch 262/400\n",
            "238/238 [==============================] - 14s 60ms/step - loss: 0.9453\n",
            "Epoch 263/400\n",
            "154/238 [==================>...........] - ETA: 4s - loss: 0.9261Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vT4KjJ22IXGS",
        "outputId": "82206881-6143-4e59-c716-8ce519e2b709"
      },
      "source": [
        "start_chat(6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Задайте вопрос : как дела?\n",
            " за да нет, и я не теперь я еще а что вы сказал \n",
            "Задайте вопрос : что ты сказал?\n",
            " я хочу к вот же он не увидишь. \n",
            "Задайте вопрос : ок, ну и ответ\n",
            " а ты так это на же все за что? \n",
            "Задайте вопрос : привет\n",
            " что вы имеете в виду? \n",
            "Задайте вопрос : а ничего\n",
            " еще я ты уже и все. \n",
            "Задайте вопрос : ты кличко?\n",
            " я это да, к в как совсем в ни ну, \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5Q5VT4GGwdw"
      },
      "source": [
        "## Знаки препинания отдельно"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYuVVGtHDCFr"
      },
      "source": [
        "######################\n",
        "# Подключаем керасовский токенизатор и собираем словарь индексов\n",
        "######################\n",
        "\n",
        "# print(len(questions))\n",
        "# maxWordsCount = 5000\n",
        "tokenizer = Tokenizer(filters='\"#$%&()*+/<=>@[\\\\]^_`{|}~\\t\\n', oov_token='unknown', char_level=False, split=' ')\n",
        "to_tokenize = '.,:;!?'\n",
        "\n",
        "for i in range(len(questions)):\n",
        "  # print(str(type(questions[i]))+ str(i))\n",
        "  if type(questions[i]) == list:\n",
        "    questions[i] = re.sub(r'(['+to_tokenize+'])', r' \\1', questions[i][0])\n",
        "  else:\n",
        "    questions[i] = re.sub(r'(['+to_tokenize+'])', r' \\1', questions[i])\n",
        "for i in range(len(answers)):\n",
        "  # print(str(type(questions[i]))+ str(i))\n",
        "  if type(answers[i]) == list:\n",
        "    answers[i] = re.sub(r'(['+to_tokenize+'])', r' \\1', answers[i][0])\n",
        "  else:\n",
        "    answers[i] = re.sub(r'(['+to_tokenize+'])', r' \\1', answers[i])\n",
        "# questions = re.sub(r'(['+to_tokenize+'])', r' \\1', str(questions))\n",
        "# answers = re.sub(r'(['+to_tokenize+'])', r' \\1', str(answers))\n",
        "# questions_splited = questions_splited.split()\n",
        "# answers_splited = answers_splited.split()\n",
        "# print(len(questions))\n",
        "tokenizer.fit_on_texts(questions + answers) # загружаем в токенизатор список вопросов-ответов для сборки словаря частотности\n",
        "vocabularyItems = list(tokenizer.word_index.items()) # список с cодержимым словаря\n",
        "\n",
        "vocabularySize = len(vocabularyItems)+1 # размер словаря\n",
        "del vocabularyItems\n",
        "# print( 'Фрагмент словаря : {}'.format(vocabularyItems[:50]))\n",
        "# print( 'Размер словаря : {}'.format(vocabularySize))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rHYsH24CsO-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce2ca0a9-7882-4bcc-947f-67e1e5e9f95a"
      },
      "source": [
        "######################\n",
        "# Устанавливаем закодированные входные данные(вопросы)\n",
        "######################\n",
        "tokenizedQuestions = tokenizer.texts_to_sequences(questions) # разбиваем текст вопросов на последовательности индексов\n",
        "maxLenQuestions = max([ len(x) for x in tokenizedQuestions]) # уточняем длину самого большого вопроса\n",
        "# Делаем последовательности одной длины, заполняя нулями более короткие вопросы\n",
        "paddedQuestions = pad_sequences(tokenizedQuestions, maxlen=maxLenQuestions, padding='post')\n",
        "\n",
        "# Предподготавливаем данные для входа в сеть\n",
        "encoderForInput = np.array(paddedQuestions) # переводим в numpy массив\n",
        "print('Пример оригинального вопроса на вход : {}'.format(questions[100])) \n",
        "print('Пример кодированного вопроса на вход : {}'.format(encoderForInput[100])) \n",
        "print('Размеры закодированного массива вопросов на вход : {}'.format(encoderForInput.shape)) \n",
        "print('Установленная длина вопросов на вход : {}'.format(maxLenQuestions)) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Пример оригинального вопроса на вход : Какая же мораль ?\n",
            "Пример кодированного вопроса на вход : [ 197   23 5740    5    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0]\n",
            "Размеры закодированного массива вопросов на вход : (11900, 19)\n",
            "Установленная длина вопросов на вход : 19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SDKjWDICsPD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6280426-6296-4ba2-a01b-5b3efd4720c8"
      },
      "source": [
        "######################\n",
        "# Устанавливаем раскодированные входные данные(ответы)\n",
        "######################\n",
        "tokenizedAnswers = tokenizer.texts_to_sequences(answers) # разбиваем текст ответов на последовательности индексов\n",
        "maxLenAnswers = max([len(x) for x in tokenizedAnswers]) # уточняем длину самого большого ответа\n",
        "# Делаем последовательности одной длины, заполняя нулями более короткие ответы\n",
        "paddedAnswers = pad_sequences(tokenizedAnswers, maxlen=maxLenAnswers, padding='post')\n",
        "\n",
        "# Предподготавливаем данные для входа в сеть\n",
        "decoderForInput = np.array(paddedAnswers) # переводим в numpy массив\n",
        "print('Пример оригинального ответа на вход: {}'.format(answers[100])) \n",
        "print('Пример раскодированного ответа на вход : {}'.format(decoderForInput[100][:30])) \n",
        "print('Размеры раскодированного массива ответов на вход : {}'.format(decoderForInput.shape)) \n",
        "print('Установленная длина ответов на вход : {}'.format(maxLenAnswers)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Пример оригинального ответа на вход: <START> Никакой . Так просто вспомнилось . <END>\n",
            "Пример раскодированного ответа на вход : [    3   670     2    24    97 10694     2     4     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0]\n",
            "Размеры раскодированного массива ответов на вход : (11900, 28)\n",
            "Установленная длина ответов на вход : 28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSkd9jqdCsPH"
      },
      "source": [
        "######################\n",
        "# Раскодированные выходные данные(ответы)\n",
        "######################\n",
        "tokenizedAnswers = tokenizer.texts_to_sequences(answers) # разбиваем текст ответов на последовательности индексов\n",
        "for i in range(len(tokenizedAnswers)) : # для разбитых на последовательности ответов\n",
        "  tokenizedAnswers[i] = tokenizedAnswers[i][1:] # избавляемся от тега <START>\n",
        "# Делаем последовательности одной длины, заполняя нулями более короткие ответы\n",
        "paddedAnswers = pad_sequences(tokenizedAnswers, maxlen=maxLenAnswers , padding='post')\n",
        "\n",
        "decoderForOutput = utils.to_categorical(paddedAnswers, vocabularySize) # переводим в one hot vector\n",
        "# decoderForOutput = np.array(oneHotAnswers) # и сохраняем в виде массива numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1JQoSHSGQdZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3234b81a-c45b-4815-bc1b-7eaf0eb15d6c"
      },
      "source": [
        "type(decoderForOutput)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfUE_B6vCsPK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34c2f941-9492-42ed-9668-e716cacf5256"
      },
      "source": [
        "print('Пример раскодированного ответа на вход : {}'.format(decoderForInput[100][:21]))  \n",
        "print('Пример раскодированного ответа на выход : {}'.format(decoderForOutput[100][4][:21])) \n",
        "print('Размеры раскодированного массива ответов на выход : {}'.format(decoderForOutput.shape))\n",
        "print('Установленная длина вопросов на выход : {}'.format(maxLenAnswers)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Пример раскодированного ответа на вход : [    3   670     2    24    97 10694     2     4     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0]\n",
            "Пример раскодированного ответа на выход : [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Размеры раскодированного массива ответов на выход : (11900, 28, 15337)\n",
            "Установленная длина вопросов на выход : 28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_DhYUl-CsPO"
      },
      "source": [
        "######################\n",
        "# Создадим функцию, которая преобразует вопрос пользователя в последовательность индексов\n",
        "######################\n",
        "def strToTokens(sentence: str): # функция принимает строку на вход (предложение с вопросом)\n",
        "  words = sentence.lower().split() # приводит предложение к нижнему регистру и разбирает на слова\n",
        "  tokensList = list() # здесь будет последовательность токенов/индексов\n",
        "  for word in words: # для каждого слова в предложении\n",
        "    tokensList.append(tokenizer.texts_to_sequences([word])[0][0])  # изменено для неизвестных словарю слов\n",
        "    # tokensList.append(tokenizer.word_index[word]) # определяем токенизатором индекс и добавляем в список\n",
        "\n",
        "    # Функция вернёт вопрос в виде последовательности индексов, ограниченной длиной самого длинного вопроса из нашей базы вопросов\n",
        "  return pad_sequences([tokensList], maxlen=maxLenQuestions , padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3e0RPEfCsPS"
      },
      "source": [
        "######################\n",
        "# Создаем рабочую модель для вывода ответов на запросы пользователя\n",
        "######################\n",
        "def makeInferenceModels():\n",
        "  # Определим модель кодера, на входе далее будут закодированные вопросы(encoderForInputs), на выходе состояния state_h, state_c\n",
        "  encoderModel = Model(encoderInputs, encoderStates) \n",
        "\n",
        "  decoderStateInput_h = Input(shape=(200 ,)) # обозначим размерность для входного слоя с состоянием state_h\n",
        "  decoderStateInput_c = Input(shape=(200 ,)) # обозначим размерность для входного слоя с состоянием state_c\n",
        "\n",
        "  decoderStatesInputs = [decoderStateInput_h, decoderStateInput_c] # возьмем оба inputs вместе и запишем в decoderStatesInputs\n",
        "\n",
        "  # Берём ответы, прошедшие через эмбединг, вместе с состояниями и подаём LSTM cлою\n",
        "  decoderOutputs, state_h, state_c = decoderLSTM(decoderEmbedding, initial_state=decoderStatesInputs)\n",
        "  decoderStates = [state_h, state_c] # LSTM даст нам новые состояния\n",
        "  decoderOutputs = decoderDense(decoderOutputs) # и ответы, которые мы пропустим через полносвязный слой с софтмаксом\n",
        "\n",
        "  # Определим модель декодера, на входе далее будут раскодированные ответы (decoderForInputs) и состояния\n",
        "  # на выходе предсказываемый ответ и новые состояния\n",
        "  decoderModel = Model([decoderInputs] + decoderStatesInputs, [decoderOutputs] + decoderStates)\n",
        "\n",
        "  return encoderModel , decoderModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCSyO8n3CsPV"
      },
      "source": [
        "######################\n",
        "# Первый входной слой, кодер, выходной слой\n",
        "######################\n",
        "encoderInputs = Input(shape=(None , )) # размеры на входе сетки (здесь будет encoderForInput)\n",
        "# Эти данные проходят через слой Embedding (длина словаря, размерность) \n",
        "encoderEmbedding = Embedding(vocabularySize, 200 , mask_zero=True) (encoderInputs)\n",
        "# Затем выход с Embedding пойдёт в LSTM слой, на выходе у которого будет два вектора состояния - state_h , state_c\n",
        "# Вектора состояния - state_h , state_c зададутся в LSTM слое декодера в блоке ниже\n",
        "encoderOutputs, state_h , state_c = LSTM(200, return_state=True)(encoderEmbedding)\n",
        "encoderStates = [state_h, state_c]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsqNTFQKCsPX"
      },
      "source": [
        "######################\n",
        "# Второй входной слой, декодер, выходной слой\n",
        "######################\n",
        "decoderInputs = Input(shape=(None, )) # размеры на входе сетки (здесь будет decoderForInput)\n",
        "# Эти данные проходят через слой Embedding (длина словаря, размерность) \n",
        "# mask_zero=True - игнорировать нулевые padding при передаче в LSTM. Предотвратит вывод ответа типа: \"У меня все хорошо PAD PAD PAD PAD PAD PAD..\"\n",
        "decoderEmbedding = Embedding(vocabularySize, 200, mask_zero=True) (decoderInputs) \n",
        "# Затем выход с Embedding пойдёт в LSTM слой, которому передаются вектора состояния - state_h , state_c\n",
        "decoderLSTM = LSTM(200, return_state=True, return_sequences=True)\n",
        "decoderOutputs , _ , _ = decoderLSTM (decoderEmbedding, initial_state=encoderStates)\n",
        "# И от LSTM'а сигнал decoderOutputs пропускаем через полносвязный слой с софтмаксом на выходе\n",
        "decoderDense = Dense(vocabularySize, activation='softmax') \n",
        "output = decoderDense (decoderOutputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gPAWMspCsPa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 891
        },
        "outputId": "7bb316ca-9e47-4a8e-e44a-398ebb4682cb"
      },
      "source": [
        "######################\n",
        "# Собираем тренировочную модель нейросети\n",
        "######################\n",
        "model = Model([encoderInputs, decoderInputs], output)\n",
        "model.compile(optimizer=RMSprop(), loss='categorical_crossentropy')\n",
        "\n",
        "print(model.summary()) # выведем на экран информацию о построенной модели нейросети\n",
        "plot_model(model, to_file='model.png') # и построим график для визуализации слоев и связей между ними"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 200)    3067400     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 200)    3067400     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 200), (None, 320800      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 200),  320800      embedding_1[0][0]                \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 15337)  3082737     lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 9,859,137\n",
            "Trainable params: 9,859,137\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qzlkTHInOsg",
        "outputId": "dfb1100c-c4bd-4baf-abbb-9b47c4652f5e"
      },
      "source": [
        "model.fit([encoderForInput , decoderForInput], decoderForOutput, batch_size=50, epochs=400) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.8144\n",
            "Epoch 2/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.7989\n",
            "Epoch 3/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.7841\n",
            "Epoch 4/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.7690\n",
            "Epoch 5/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.7545\n",
            "Epoch 6/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.7401\n",
            "Epoch 7/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.7257\n",
            "Epoch 8/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.7113\n",
            "Epoch 9/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.6979\n",
            "Epoch 10/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.6849\n",
            "Epoch 11/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.6716\n",
            "Epoch 12/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.6588\n",
            "Epoch 13/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.6463\n",
            "Epoch 14/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.6349\n",
            "Epoch 15/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.6232\n",
            "Epoch 16/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.6117\n",
            "Epoch 17/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.6011\n",
            "Epoch 18/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.5901\n",
            "Epoch 19/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.5801\n",
            "Epoch 20/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.5703\n",
            "Epoch 21/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.5596\n",
            "Epoch 22/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.5489\n",
            "Epoch 23/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.5387\n",
            "Epoch 24/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.5296\n",
            "Epoch 25/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.5209\n",
            "Epoch 26/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.5130\n",
            "Epoch 27/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.5052\n",
            "Epoch 28/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.4983\n",
            "Epoch 29/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.4902\n",
            "Epoch 30/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.4836\n",
            "Epoch 31/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.4769\n",
            "Epoch 32/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.4713\n",
            "Epoch 33/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.4657\n",
            "Epoch 34/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.4605\n",
            "Epoch 35/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.4549\n",
            "Epoch 36/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.4496\n",
            "Epoch 37/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.4445\n",
            "Epoch 38/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.4392\n",
            "Epoch 39/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.4343\n",
            "Epoch 40/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.4293\n",
            "Epoch 41/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.4243\n",
            "Epoch 42/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.4199\n",
            "Epoch 43/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.4159\n",
            "Epoch 44/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.4121\n",
            "Epoch 45/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.4088\n",
            "Epoch 46/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.4055\n",
            "Epoch 47/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.4025\n",
            "Epoch 48/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3999\n",
            "Epoch 49/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.3974\n",
            "Epoch 50/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3948\n",
            "Epoch 51/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3924\n",
            "Epoch 52/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.3896\n",
            "Epoch 53/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3863\n",
            "Epoch 54/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3833\n",
            "Epoch 55/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3801\n",
            "Epoch 56/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3774\n",
            "Epoch 57/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3753\n",
            "Epoch 58/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3737\n",
            "Epoch 59/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3716\n",
            "Epoch 60/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3704\n",
            "Epoch 61/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3686\n",
            "Epoch 62/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3676\n",
            "Epoch 63/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.3660\n",
            "Epoch 64/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3645\n",
            "Epoch 65/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3622\n",
            "Epoch 66/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3605\n",
            "Epoch 67/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3582\n",
            "Epoch 68/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3568\n",
            "Epoch 69/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3549\n",
            "Epoch 70/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.3531\n",
            "Epoch 71/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3514\n",
            "Epoch 72/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3497\n",
            "Epoch 73/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.3482\n",
            "Epoch 74/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.3462\n",
            "Epoch 75/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3447\n",
            "Epoch 76/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3434\n",
            "Epoch 77/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3422\n",
            "Epoch 78/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3410\n",
            "Epoch 79/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.3402\n",
            "Epoch 80/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3393\n",
            "Epoch 81/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3382\n",
            "Epoch 82/400\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.3373\n",
            "Epoch 83/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3363\n",
            "Epoch 84/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3348\n",
            "Epoch 85/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.3336\n",
            "Epoch 86/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3326\n",
            "Epoch 87/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3308\n",
            "Epoch 88/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3297\n",
            "Epoch 89/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.3285\n",
            "Epoch 90/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3271\n",
            "Epoch 91/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3260\n",
            "Epoch 92/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3248\n",
            "Epoch 93/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3237\n",
            "Epoch 94/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3221\n",
            "Epoch 95/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3208\n",
            "Epoch 96/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3200\n",
            "Epoch 97/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3184\n",
            "Epoch 98/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3171\n",
            "Epoch 99/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3161\n",
            "Epoch 100/400\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.3146\n",
            "Epoch 101/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.3141\n",
            "Epoch 102/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3131\n",
            "Epoch 103/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.3121\n",
            "Epoch 104/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.3108\n",
            "Epoch 105/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3098\n",
            "Epoch 106/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.3090\n",
            "Epoch 107/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.3079\n",
            "Epoch 108/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3067\n",
            "Epoch 109/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.3059\n",
            "Epoch 110/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.3051\n",
            "Epoch 111/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3043\n",
            "Epoch 112/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.3032\n",
            "Epoch 113/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.3025\n",
            "Epoch 114/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.3016\n",
            "Epoch 115/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.3009\n",
            "Epoch 116/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2997\n",
            "Epoch 117/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2991\n",
            "Epoch 118/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2983\n",
            "Epoch 119/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2974\n",
            "Epoch 120/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2966\n",
            "Epoch 121/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2954\n",
            "Epoch 122/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2947\n",
            "Epoch 123/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2937\n",
            "Epoch 124/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2927\n",
            "Epoch 125/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2920\n",
            "Epoch 126/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2913\n",
            "Epoch 127/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2902\n",
            "Epoch 128/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2893\n",
            "Epoch 129/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2884\n",
            "Epoch 130/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2875\n",
            "Epoch 131/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2864\n",
            "Epoch 132/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2858\n",
            "Epoch 133/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2844\n",
            "Epoch 134/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2837\n",
            "Epoch 135/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2830\n",
            "Epoch 136/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2820\n",
            "Epoch 137/400\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.2814\n",
            "Epoch 138/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2801\n",
            "Epoch 139/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2794\n",
            "Epoch 140/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2784\n",
            "Epoch 141/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2778\n",
            "Epoch 142/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2767\n",
            "Epoch 143/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2757\n",
            "Epoch 144/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2749\n",
            "Epoch 145/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2746\n",
            "Epoch 146/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2733\n",
            "Epoch 147/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2725\n",
            "Epoch 148/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2716\n",
            "Epoch 149/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2711\n",
            "Epoch 150/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2703\n",
            "Epoch 151/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2694\n",
            "Epoch 152/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2685\n",
            "Epoch 153/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2678\n",
            "Epoch 154/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2670\n",
            "Epoch 155/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2661\n",
            "Epoch 156/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2656\n",
            "Epoch 157/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2648\n",
            "Epoch 158/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2639\n",
            "Epoch 159/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2629\n",
            "Epoch 160/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2623\n",
            "Epoch 161/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2615\n",
            "Epoch 162/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2608\n",
            "Epoch 163/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2600\n",
            "Epoch 164/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2592\n",
            "Epoch 165/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2585\n",
            "Epoch 166/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2582\n",
            "Epoch 167/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2574\n",
            "Epoch 168/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2569\n",
            "Epoch 169/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2561\n",
            "Epoch 170/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2555\n",
            "Epoch 171/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2548\n",
            "Epoch 172/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2543\n",
            "Epoch 173/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2536\n",
            "Epoch 174/400\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.2532\n",
            "Epoch 175/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2527\n",
            "Epoch 176/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2524\n",
            "Epoch 177/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2517\n",
            "Epoch 178/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2509\n",
            "Epoch 179/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2505\n",
            "Epoch 180/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2498\n",
            "Epoch 181/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2493\n",
            "Epoch 182/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2488\n",
            "Epoch 183/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2482\n",
            "Epoch 184/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2478\n",
            "Epoch 185/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2471\n",
            "Epoch 186/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2466\n",
            "Epoch 187/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2459\n",
            "Epoch 188/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2455\n",
            "Epoch 189/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2450\n",
            "Epoch 190/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2446\n",
            "Epoch 191/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2440\n",
            "Epoch 192/400\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.2437\n",
            "Epoch 193/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2435\n",
            "Epoch 194/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2428\n",
            "Epoch 195/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2424\n",
            "Epoch 196/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2419\n",
            "Epoch 197/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2415\n",
            "Epoch 198/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2411\n",
            "Epoch 199/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2403\n",
            "Epoch 200/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2399\n",
            "Epoch 201/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2396\n",
            "Epoch 202/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2389\n",
            "Epoch 203/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2389\n",
            "Epoch 204/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2386\n",
            "Epoch 205/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2379\n",
            "Epoch 206/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2372\n",
            "Epoch 207/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2372\n",
            "Epoch 208/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2370\n",
            "Epoch 209/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2363\n",
            "Epoch 210/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2359\n",
            "Epoch 211/400\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.2354\n",
            "Epoch 212/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2351\n",
            "Epoch 213/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2348\n",
            "Epoch 214/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2345\n",
            "Epoch 215/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2340\n",
            "Epoch 216/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2338\n",
            "Epoch 217/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2336\n",
            "Epoch 218/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2331\n",
            "Epoch 219/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2324\n",
            "Epoch 220/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2327\n",
            "Epoch 221/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2319\n",
            "Epoch 222/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2315\n",
            "Epoch 223/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2314\n",
            "Epoch 224/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2313\n",
            "Epoch 225/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2307\n",
            "Epoch 226/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2308\n",
            "Epoch 227/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2303\n",
            "Epoch 228/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2300\n",
            "Epoch 229/400\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.2299\n",
            "Epoch 230/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2294\n",
            "Epoch 231/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2294\n",
            "Epoch 232/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2289\n",
            "Epoch 233/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2287\n",
            "Epoch 234/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2287\n",
            "Epoch 235/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2282\n",
            "Epoch 236/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2279\n",
            "Epoch 237/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2277\n",
            "Epoch 238/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2273\n",
            "Epoch 239/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2274\n",
            "Epoch 240/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2271\n",
            "Epoch 241/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2268\n",
            "Epoch 242/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2266\n",
            "Epoch 243/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2261\n",
            "Epoch 244/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2261\n",
            "Epoch 245/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2262\n",
            "Epoch 246/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2260\n",
            "Epoch 247/400\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.2255\n",
            "Epoch 248/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2258\n",
            "Epoch 249/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2254\n",
            "Epoch 250/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2252\n",
            "Epoch 251/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2252\n",
            "Epoch 252/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2251\n",
            "Epoch 253/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2249\n",
            "Epoch 254/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2247\n",
            "Epoch 255/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2244\n",
            "Epoch 256/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2247\n",
            "Epoch 257/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2242\n",
            "Epoch 258/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2242\n",
            "Epoch 259/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2245\n",
            "Epoch 260/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2243\n",
            "Epoch 261/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2241\n",
            "Epoch 262/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2240\n",
            "Epoch 263/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2241\n",
            "Epoch 264/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2238\n",
            "Epoch 265/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2238\n",
            "Epoch 266/400\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.2234\n",
            "Epoch 267/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2236\n",
            "Epoch 268/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2234\n",
            "Epoch 269/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2234\n",
            "Epoch 270/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2229\n",
            "Epoch 271/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2234\n",
            "Epoch 272/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2229\n",
            "Epoch 273/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2227\n",
            "Epoch 274/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2225\n",
            "Epoch 275/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2221\n",
            "Epoch 276/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2224\n",
            "Epoch 277/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2220\n",
            "Epoch 278/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2220\n",
            "Epoch 279/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2218\n",
            "Epoch 280/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2219\n",
            "Epoch 281/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2218\n",
            "Epoch 282/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2216\n",
            "Epoch 283/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2214\n",
            "Epoch 284/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2212\n",
            "Epoch 285/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2214\n",
            "Epoch 286/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2214\n",
            "Epoch 287/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2210\n",
            "Epoch 288/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2213\n",
            "Epoch 289/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2208\n",
            "Epoch 290/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2212\n",
            "Epoch 291/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2208\n",
            "Epoch 292/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2209\n",
            "Epoch 293/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2211\n",
            "Epoch 294/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2210\n",
            "Epoch 295/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2211\n",
            "Epoch 296/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2209\n",
            "Epoch 297/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2209\n",
            "Epoch 298/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2212\n",
            "Epoch 299/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2212\n",
            "Epoch 300/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2211\n",
            "Epoch 301/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2210\n",
            "Epoch 302/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2210\n",
            "Epoch 303/400\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.2213\n",
            "Epoch 304/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2210\n",
            "Epoch 305/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2210\n",
            "Epoch 306/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2212\n",
            "Epoch 307/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2213\n",
            "Epoch 308/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2216\n",
            "Epoch 309/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2218\n",
            "Epoch 310/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2216\n",
            "Epoch 311/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2216\n",
            "Epoch 312/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2219\n",
            "Epoch 313/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2218\n",
            "Epoch 314/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2216\n",
            "Epoch 315/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2220\n",
            "Epoch 316/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2220\n",
            "Epoch 317/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2224\n",
            "Epoch 318/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2222\n",
            "Epoch 319/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2221\n",
            "Epoch 320/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2225\n",
            "Epoch 321/400\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.2223\n",
            "Epoch 322/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2221\n",
            "Epoch 323/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2224\n",
            "Epoch 324/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2225\n",
            "Epoch 325/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2227\n",
            "Epoch 326/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2227\n",
            "Epoch 327/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2230\n",
            "Epoch 328/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2228\n",
            "Epoch 329/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2230\n",
            "Epoch 330/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2232\n",
            "Epoch 331/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2230\n",
            "Epoch 332/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2229\n",
            "Epoch 333/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2231\n",
            "Epoch 334/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2232\n",
            "Epoch 335/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2229\n",
            "Epoch 336/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2230\n",
            "Epoch 337/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2229\n",
            "Epoch 338/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2233\n",
            "Epoch 339/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2231\n",
            "Epoch 340/400\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.2230\n",
            "Epoch 341/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2232\n",
            "Epoch 342/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2232\n",
            "Epoch 343/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2230\n",
            "Epoch 344/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2230\n",
            "Epoch 345/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2229\n",
            "Epoch 346/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2228\n",
            "Epoch 347/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2229\n",
            "Epoch 348/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2227\n",
            "Epoch 349/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2229\n",
            "Epoch 350/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2228\n",
            "Epoch 351/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2230\n",
            "Epoch 352/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2227\n",
            "Epoch 353/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2229\n",
            "Epoch 354/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2229\n",
            "Epoch 355/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2232\n",
            "Epoch 356/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2230\n",
            "Epoch 357/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2228\n",
            "Epoch 358/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2228\n",
            "Epoch 359/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2225\n",
            "Epoch 360/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2228\n",
            "Epoch 361/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2223\n",
            "Epoch 362/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2227\n",
            "Epoch 363/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2226\n",
            "Epoch 364/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2225\n",
            "Epoch 365/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2225\n",
            "Epoch 366/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2226\n",
            "Epoch 367/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2224\n",
            "Epoch 368/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2224\n",
            "Epoch 369/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2224\n",
            "Epoch 370/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2225\n",
            "Epoch 371/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2227\n",
            "Epoch 372/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2227\n",
            "Epoch 373/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2227\n",
            "Epoch 374/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2225\n",
            "Epoch 375/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2222\n",
            "Epoch 376/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2222\n",
            "Epoch 377/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2222\n",
            "Epoch 378/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2218\n",
            "Epoch 379/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2218\n",
            "Epoch 380/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2219\n",
            "Epoch 381/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2219\n",
            "Epoch 382/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2219\n",
            "Epoch 383/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2220\n",
            "Epoch 384/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2218\n",
            "Epoch 385/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2215\n",
            "Epoch 386/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2215\n",
            "Epoch 387/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2215\n",
            "Epoch 388/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2215\n",
            "Epoch 389/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2213\n",
            "Epoch 390/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2216\n",
            "Epoch 391/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2214\n",
            "Epoch 392/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2213\n",
            "Epoch 393/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2212\n",
            "Epoch 394/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2216\n",
            "Epoch 395/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2213\n",
            "Epoch 396/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2212\n",
            "Epoch 397/400\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.2211\n",
            "Epoch 398/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2212\n",
            "Epoch 399/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2213\n",
            "Epoch 400/400\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.2209\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4a8001f978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGJbwCGoH3po",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7107805a-f41a-4ddd-a6d7-d8d06b4d9e8d"
      },
      "source": [
        "start_chat(6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Задайте вопрос : как дела ?\n",
            " за ночь сделали пятнадцать ничего . \n",
            "Задайте вопрос : молодцы ! а почему так мало ?\n",
            " не имеет значения . \n",
            "Задайте вопрос : ты почему такой дерзкий ?\n",
            " что я хочу делаешь в этом тобой ? \n",
            "Задайте вопрос : сколько вешать в граммах ?\n",
            " двадцать две очень . и джон не каком ним ? \n",
            "Задайте вопрос : я не понимаю тебя\n",
            " не я не . \n",
            "Задайте вопрос : пойдем гулять ?\n",
            " оба . . . же не делать , дальше ? \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oTomH8Njdxj",
        "outputId": "7a738df4-0088-4ec3-8e3d-f7f8d147dd57"
      },
      "source": [
        "start_chat(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Задайте вопрос : как дела ?\n",
            " за ночь сделали пятнадцать . \n",
            "Задайте вопрос : молодцы ! а почему так мало ?\n",
            " не слишком поздно . \n",
            "Задайте вопрос : ты почему такой дерзкий ?\n",
            " да так . \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}