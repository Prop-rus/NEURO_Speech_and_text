Домашнее задание к занятию 27
Сегментация текста

Light задание. Вариант 1
 
Сделайте свою собственную архитектуру и запустите, оцените точность на проверочной выборке
Возьмите “лучшую” архитектуру и проведите несколько экспериментов, меняя гиперпараметры выбранной архитектуры.
Напишите ваши выводы
 
 
Pro задание. Вариант 1
Используйте другие методы обработки текста (которых не было в занятии, например, embedding слой), поменяйте параметры UNET (или любой другой архитектуры) с занятия и добейтесь с ними точности 85% по среднему показателю распознавания или 0.65 для val_dice_coef


Pro задание. Вариант 2
Реализуйте сегментацию на расширенной выборке договоров и добейтесь точности 85% по среднему показателю распознавания или 0.65 для val_dice_coef
 
 
Pro задание. Вариант 3
Преобразовать предсказания сети в понимаемый человеком формат


Домашнее задание к занятию 26. 
Генерация текста.

Light задание 1
1) Используя три любых простых вопроса, сравните ответы сети на них на разной степени натренированности:
a) 20 эпох – удается ли боту отвечать целыми словами?
b) + 30 эпох на этой же сетке и с этими же вопросами – появился ли прогресс в качестве ответа сети(ответ целыми предложениями разумной длины)?
c) Ещё + 50 эпох – удается ли сети выдавать ответы, “похожие на правду”?

Light задание 2
 Попробуйте сделать любой небольшой набор диалогов(используем тот же формат файла и способ хранения фраз: “ - - Вопрос” и “  - Ответ”) и использовать его на этой же сетке. Проведите наблюдения:
а) Насколько быстрее обучается сетка
b) Способна ли она выдавать “адекватные” ответы
с) Ответы выглядят просто заученными под копирку или можно сказать, что генерируется что-то новое? 

PRO задание #1
1) Попробуйте улучшить текущий скрипт чат-бота, внедрив блок кода для присвоения словам вне словаря(out-of-vocabulary) метки “unknown” так, чтобы встретив в запросе незнакомое слово, исполнение кода не останавливалось, а продолжалось, игнорируя “unknown” слова.

2) Текущая модель не учитывает знаки препинания в диалоге. Скорректируйте некоторые блоки кода так, чтобы они учитывались. Проведите наблюдения, как добавление знаков скажется на работе и результатах сетки.

PRO задание #2 (альтернативное на выбор)
Добейтесь максимально низкого Loss’а в обучении модели, экспериментируя с архитектурой и параметрами сети(размеры пространства эмбеддинга, слоев сетки, разные оптимайзеры и т.п) 




Домашнее задание к занятию 33. Распознавание речи.

Light задание

Используя микрофон, запишите несколько аналогичных команд своим голосом и проверьте результат работы предсказания сетки. Сделайте вывод о дикторозависимости в такой модели
Используя микрофон, запишите и добавьте в текущую базу по 5-10 команд своим голосом и проверьте результаты работы сетки на обновленной базе

PRO задание #1 
Меняя параметры/гиперпараметры модели и подход к формированию выборки, добейтесь максимальной точности сетки. 


Домашнее задание к занятию 18
Рекуррентные сети и одномерная свёртка для обработки текстов

Light задание
Используя шаблон ноутбука, напишите четыре нейронки для распознавания писателей. Для этого выполните следующее:
Загрузите данные и разделите на слова.
Создайте словарь и превратите данные в индексы.
Превратите данные в обучающую выборку.
Напишите нейронные сети.

Четыре нейронки, которые нужно написать:
Embedding + Dense сеть.
Embedding + LSTM сеть.
Embedding + Conv1D сеть.
Embedding + сложная сеть из Dense, LSTM и Conv1D.

Для выполнения задания можно смотреть в ноутбук задания, но код желательно писать своими руками, а не копировать.


PRO задание. Вариант 1
Напишите классификацию заболеваний по базе симптомов, используя любые подходы, связанные с обработкой текстов.
Embedding + LSTM сеть.
Embedding + Conv1D сеть.
Embedding + сложная сеть из Dense, LSTM и Conv1D.
Добейтесь максимальной точности распознавания.
Используйте xLen = 50.


PRO задание. Вариант 2
Сделайте оценку того, как блоки слов в словаре влияют на точность классификации (на любой базе, например, распознавание писателей). Для этого выполните следующее:
Сформируйте словарь.
Используйте первые 50000 слов.
Разбейте все слова на блоки по 100 слов последовательно.
Поочередно отключайте блоки по одному, то есть сделайте так, чтобы эти слова не использовались при обучении сети, например, их индексы всегда приравнивались к 0.
Оцените, как меняется точность классификации на проверочной выборке.
Сделайте выводы, какие блоки слов влияют в плюс, а какие в минус.
Соберите итоговую подборку слов, в которую войдут только те блоки по 100 слов, которые улучшили точность (исключение которых давало падение точности).
Обучите сеть только на этих блоках слов.
Оцените изменение точности в сравнении с обучением на полном словаре (первые 50000 слов).


ДОМАШНЕЕ ЗАДАНИЕ №17
апрельский курс - 2020 Light

LIGHT
Вариант 1
Выполните задания, по каждому варианту напишите точность распознавания на проверочной выборке и сделайте выводы.
Запустите нейронку c bag of words (01) при разных maxWordsCount
100
1000
10000
50000
Запустите нейронку c bag of words (01) при maxWordsCount = 20000 и разных архитектурах
Поменяйте количество нейронов в слоях
Поменяйте количество слоев
Поменяйте активационные функции слоев
Запустите нейронку c Embbedding при maxWordsCount = 50000, поменяйте размер Embedding пространства
10
50
200
PRO
Вариант 1
Добейтесь точности распознавания 96% и верно распознанных всех писателей с помощью любой нейронной сети (Попробуйте реализовать это без фильтрации данных). 
Вариант 2
Используйте разбиение текстов на фрагменты на базе обращения граждан в органы власти, как при распознавании писателей, например, размер блока - 20 слов, шаг - 1 слово.
Сравните точность с базовым ноутбуком, проверьте 3 различных архитектур сети.
Напишите функцию распознавания нужного обращения разделением его на фрагменты и распознаванием фрагментов.
Попробуйте разные параметры фильтрации выборки. Добавьте какой-нибудь свой критерий для фильтрации.
Запишите в конце ноутбука выводы о полученных исследованиях.
